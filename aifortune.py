# -*- coding: utf-8 -*-
"""AIç®—å‘½å¸«ç³»çµ±.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jzcMrjjm6ZB8ApJ_heStpaa3sPIWFV2L

**AIç®—å‘½å¸«ç³»çµ±**  
èªªæ˜: RAG + Groq å¦è±¡å•ç­”ç³»çµ± åŠ ä¸Šã€Œéš¨æ©Ÿèµ·å¦ã€åŠŸèƒ½ï¼Œè®“ä½¿ç”¨è€…åªè¼¸å…¥ä¸€å€‹å•é¡Œï¼Œç³»çµ±æœƒ:

1. éš¨æ©Ÿç”¢ç”Ÿå¦è±¡ï¼ˆ6 å€‹çˆ»ï¼Œæ¯å€‹çˆ»å¯èƒ½è®Šå‹•ï¼‰

2. æ‰¾å‡ºå¦è±¡èˆ‡å‹•çˆ»

3. æ•´åˆé€² prompt â†’ ä¸Ÿçµ¦æ¨¡å‹ç”Ÿæˆå›ç­”

**èµ·å¦æ–¹å¼ï¼ˆéš¨æ©Ÿæ³•ï¼‰èªªæ˜**  

æ¯ä¸€çˆ»æœƒæ˜¯ä»¥ä¸‹å››ç¨®ä¹‹ä¸€ï¼ˆéŠ…éŒ¢æ³•è½‰æ›ï¼‰ï¼š

6ï¼šé™°çˆ»è®Šï¼ˆâš‹ â†’ âšŠï¼‰

7ï¼šé™½çˆ»ä¸è®Šï¼ˆâšŠï¼‰

8ï¼šé™°çˆ»ä¸è®Šï¼ˆâš‹ï¼‰

9ï¼šé™½çˆ»è®Šï¼ˆâšŠ â†’ âš‹ï¼‰

**å¯è‡ªè¡Œä¸‹è¼‰è³‡æ–™æª”**
"""

"""**è¼‰å…¥å¿…è¦å¥—ä»¶**"""
# å·²ç§»é™¤ pip install ç›¸é—œè¡Œï¼Œè«‹æ–¼å‘½ä»¤åˆ—å®‰è£ä¾è³´

import random
import json
import faiss
import numpy as np
import requests
import gradio as gr
from sentence_transformers import SentenceTransformer
import os
import logging

"""**åˆå§‹åŒ–æ¨¡å‹èˆ‡è³‡æ–™**"""

# è¨­å®š logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

# è®€å– API é‡‘é‘°
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    raise RuntimeError("è«‹è¨­å®š GROQ_API_KEY ç’°å¢ƒè®Šæ•¸ï¼Œé¿å…é‡‘é‘°æ´©æ¼ï¼")

data_path = "yijing_training_data_3000.jsonl"

"""**è¼‰å…¥ JSONL è³‡æ–™**"""

sample_data = []
with open(data_path, 'r', encoding='utf-8') as f:
    for line in f:
        item = json.loads(line)
        if "prompt" in item and "completion" in item:
            sample_data.append(item)

corpus = [item["prompt"] for item in sample_data]

"""**åµŒå…¥æ¨¡å‹èˆ‡å‘é‡è³‡æ–™åº«**"""

embed_model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = embed_model.encode(corpus, convert_to_numpy=True)
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

"""**éš¨æ©Ÿèµ·æ›**"""

yao_map = {
    6: "é™°çˆ»è®Š",
    7: "é™½çˆ»ä¸è®Š",
    8: "é™°çˆ»ä¸è®Š",
    9: "é™½çˆ»è®Š"
}

def random_hexagram():
    yaos = [random.choice([6, 7, 8, 9]) for _ in range(6)]
    yao_desc = [yao_map[y] for y in yaos]
    return yaos, yao_desc

"""**æŸ¥è©¢èªæ–™åº«**"""

def retrieve_context(query, top_k=3):
    try:
        query_embedding = embed_model.encode([query], convert_to_numpy=True)
        D, I = index.search(query_embedding, top_k)
        return "\n\n".join([sample_data[i]["completion"] for i in I[0]])
    except Exception as e:
        logging.error(f"RAG æª¢ç´¢å¤±æ•—: {e}")
        return ""

"""**å‘¼å« Groq**"""

def ask_llm(query, context):
    try:
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "llama3-8b-8192",
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ä½ å…¨ç¨‹åªæœƒä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¸”ä½ æ˜¯ä¸€ä½æ“…é•·è§£é‡‹æ˜“ç¶“å¦è±¡çš„æ™ºæ…§é¡§å•ï¼Œ"
                        "æ ¹æ“šå¦è±¡èˆ‡ä½¿ç”¨è€…å•é¡Œï¼Œçµ¦å‡ºæœ‰æ·±åº¦çš„å»ºè­°ã€‚è«‹å‹¿ä½¿ç”¨è‹±æ–‡ï¼Œæ‰€æœ‰å…§å®¹éƒ½å¿…é ˆæ˜¯ç¹é«”ä¸­æ–‡ã€‚"
                    )
                },
                {
                    "role": "user",
                    "content": f"èƒŒæ™¯è³‡æ–™å¦‚ä¸‹ï¼š\n{context}\n\nä½¿ç”¨è€…æå•ï¼š{query}"
                }
            ],
            "temperature": 0.7,
            "max_tokens": 512
        }
        response = requests.post("https://api.groq.com/openai/v1/chat/completions",
                                 headers=headers, json=payload)
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        logging.error(f"Groq API å‘¼å«å¤±æ•—: {e}")
        return f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

"""**ä¸»é‚è¼¯**"""

def hexagram_to_unicode(yaos: list[int]) -> str:
    """å°‡å…­çˆ»æ•¸å€¼è½‰æ›ç‚ºUnicodeå¦è±¡åœ–ã€‚"""
    # 6/8: é™°çˆ»ï¼ˆâš‹ï¼‰ï¼Œ7/9: é™½çˆ»ï¼ˆâšŠï¼‰
    yao_symbols = {6: 'âš‹', 7: 'âšŠ', 8: 'âš‹', 9: 'âšŠ'}
    lines = [yao_symbols.get(y, '?') for y in reversed(yaos)]  # ä¸Šçˆ»åœ¨ä¸Š
    return '\n'.join(lines)

def fortune_teller(user_question, mode, manual_yaos, manual_moving):
    try:
        if mode == "éš¨æ©Ÿèµ·å¦":
            yaos, yao_desc = random_hexagram()
        else:
            yaos = [int(x) for x in manual_yaos.split(',')]
            yao_desc = [yao_map[y] for y in yaos]
        moving_lines = [i+1 for i, y in enumerate(yaos) if y in [6, 9]]
        yao_text = f"å‹•çˆ»ï¼š{', '.join(map(str, moving_lines)) if moving_lines else 'ç„¡'}\nå…­çˆ»ç‹€æ…‹ï¼š{', '.join(yao_desc)}"
        hexagram_img = hexagram_to_unicode(yaos)
        pseudo_prompt = f"å•é¡Œï¼š{user_question}\nå¦è±¡ï¼š{'æ‰‹å‹•è¼¸å…¥' if mode=='æ‰‹å‹•è¼¸å…¥' else 'éš¨æ©Ÿå¦è±¡'}ï¼Œ{yao_text}ã€‚\n"
        context = retrieve_context(pseudo_prompt)
        answer = ask_llm(pseudo_prompt, context)
        return f"ğŸ”® æ‚¨çš„å•é¡Œï¼š{user_question}\n\nğŸ§§ å¦è±¡åœ–ï¼š\n{hexagram_img}\n\nå¦è±¡æè¿°ï¼š\n{yao_text}\n\nğŸ’¡ è§£å¦å»ºè­°ï¼š\n{answer}"
    except Exception as e:
        logging.error(f"fortune_teller åŸ·è¡Œå¤±æ•—: {e}")
        return f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

"""**Gradio UI**"""

with gr.Blocks() as demo:
    gr.Markdown("# æ¢…èŠ±å•å¦ï¼æ™ºèƒ½è§£æ˜“\nAI Plum Blossom Divination")
    mode = gr.Radio(["éš¨æ©Ÿèµ·å¦", "æ‰‹å‹•è¼¸å…¥"], label="èµ·å¦æ–¹å¼", value="éš¨æ©Ÿèµ·å¦")
    user_question = gr.Textbox(lines=2, label="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ", placeholder="ä¾‹å¦‚ï¼šæˆ‘æœ€è¿‘é©åˆæ›å·¥ä½œå—ï¼Ÿ")
    manual_yaos = gr.Textbox(label="æ‰‹å‹•è¼¸å…¥å…­çˆ»ï¼ˆä»¥é€—è™Ÿåˆ†éš”ï¼Œå¦‚7,8,9,6,7,8ï¼‰", visible=False)
    manual_moving = gr.Textbox(label="å‹•çˆ»ï¼ˆå¯ç•™ç©ºï¼Œè‡ªå‹•åˆ¤æ–·ï¼‰", visible=False)
    output = gr.Textbox(label="å¦è±¡è§£é‡‹çµæœ")

    def update_visibility(selected):
        return {manual_yaos: gr.update(visible=(selected=="æ‰‹å‹•è¼¸å…¥")),
                manual_moving: gr.update(visible=False)}

    mode.change(update_visibility, inputs=mode, outputs=[manual_yaos, manual_moving])
    btn = gr.Button("è§£å¦")
    btn.click(fortune_teller, inputs=[user_question, mode, manual_yaos, manual_moving], outputs=output)

demo.launch(share=True)